  const lower = text.toLowerCase();
  const tags: string[] = [];
  if (lower.includes("post") || lower.includes("video") || lower.includes("blog")) tags.push("content");
  if (lower.includes("sell") || lower.includes("price") || lower.includes("launch")) tags.push("offer");
  if (lower.includes("process") || lower.includes("system") || lower.includes("hire")) tags.push("ops");
  return tags;
};

// Move nested component outside to prevent re-renders
function DashboardBrainDumpSection({ businessId }: { businessId: string }) {
  // Get or create an initiative for the business (we'll read the first one)
  const initiatives = useQuery(
    api.initiatives.getByBusiness as any,
    businessId ? { businessId } : "skip",
  );
  const initiative = initiatives?.[0];
  const initiativeId = initiative?._id;

  const dumps = useQuery(
    api.initiatives.listBrainDumpsByInitiative as any,
    initiativeId ? { initiativeId, limit: 10 } : "skip",
  );

  const addDump = useMutation(api.initiatives.addBrainDump as any);
  const addVoiceDump = useMutation(api.initiatives.addVoiceBrainDump as any);
  const deleteDump = useMutation(api.initiatives.deleteBrainDump as any);
  const updateTags = useMutation(api.initiatives.updateBrainDumpTags as any);
  const softDelete = useMutation(api.initiatives.softDeleteBrainDump as any);
  const restoreDump = useMutation(api.initiatives.restoreBrainDump as any);

  const [text, setText] = React.useState("");
  const [saving, setSaving] = React.useState(false);
  const [transcript, setTranscript] = React.useState("");
  const [summary, setSummary] = React.useState("");
  // Add filter state for tag chips
  const [activeTagFilter, setActiveTagFilter] = React.useState<
    "" | "content" | "offer" | "ops"
  >("");

  // Add: inline save handler for typed idea
  const handleSaveIdeaInline = async () => {
    if (!initiativeId) {
      toast("No initiative found. Run Phase 0 setup first.");
      return;
    }
    const content = (text || summary || transcript).trim();
    if (!content) {
      toast("Type an idea first.");
      return;
    }
    try {
      setSaving(true);
      const tags = tagIdea(content);
      if (addVoiceDump) {
        await addVoiceDump({
          initiativeId,
          content,
          transcript: transcript || undefined,
          summary: summary || undefined,
          tags,
        });
      } else {
        await addDump({ initiativeId, content });
      }
      setText("");
      toast.success("Saved idea.");
    } catch (e: any) {
      toast.error(e?.message || "Failed to save idea.");
    } finally {
      setSaving(false);
    }
  };

  return (
    <div className="space-y-4">
      <div className="flex items-center gap-2">
        <Input
          placeholder="Type a quick idea..."
          value={text}
          onChange={(e) => setText(e.target.value)}
          onKeyDown={(e) => {
            if (e.key === "Enter" && !e.shiftKey) {
              e.preventDefault();
              handleSaveIdeaInline();
            }
          }}
        />
        <Button size="sm" onClick={handleSaveIdeaInline} disabled={saving}>
          {saving ? <Loader2 className="h-4 w-4 animate-spin" /> : <Plus className="h-4 w-4" />}
        </Button>
      </div>
    </div>
  );
}

function SolopreneurDashboard({ business: businessProp }: { business?: any }) {
  // Use auth status early to guard queries when not authenticated
  const { isAuthenticated: isAuthed } = useAuth();
  
  // Fetch current user data
  const user = useQuery(api.users.currentUser, isAuthed ? {} : "skip");
  
  // Determine if user is in guest mode
  const isGuest = !isAuthed;
  
  // Use business from prop
  const business = businessProp;
  
  // Add navigation hook
  const navigate = useNavigate();
  
  // Add onUpgrade callback function
  const onUpgrade = () => {
    navigate("/pricing");
  };
  
  // Local BrainDumpSection component removed and moved outside to prevent re-renders

    // Audio recording + upload + transcription
    const mediaRecorderRef = React.useRef<MediaRecorder | null>(null);
    const chunksRef = React.useRef<Blob[]>([]);
    const [audioUrl, setAudioUrl] = React.useState<string>("");
    const [uploading, setUploading] = React.useState(false);
    const getUploadUrl = useAction(api.files.getUploadUrl as any);
    /* removed duplicate voice notes robustness state block */

    // Request mic permission upfront to provide clearer UX and actionable errors.
    async function requestMicPermission() {
      try {
        // Some browsers implement navigator.permissions for microphone; gracefully fallback
        const p = (navigator as any).permissions?.query
          ? await (navigator as any).permissions.query({
              name: "microphone" as any,
            })
          : null;
        if (p && p.state) {
          setMicPermission(p.state as "prompt" | "granted" | "denied");
          p.onchange = () => setMicPermission((p as any).state);
        } else {
          setMicPermission("prompt");
        }
      } catch {
        setMicPermission("prompt");
      }
    }

    // Start recording: handle permission denial and surface nice errors.
    // This replaces the previous startVoice with a more robust version.
    async function startVoice() {
      setMicError(null);
      try {
        await requestMicPermission();
        // Try to get microphone; surface error if not available or denied
        const stream = await navigator.mediaDevices.getUserMedia({
          audio: true,
        });
        const mr = new MediaRecorder(stream);
        chunksRef.current = [];
        mr.ondataavailable = (e) => {
          if (e.data && e.data.size > 0) chunksRef.current.push(e.data);
        };
        mr.onstop = () => {
          const blob = new Blob(chunksRef.current, { type: "audio/webm" });
          const url = URL.createObjectURL(blob);
          setAudioUrl(url);
        };
        mediaRecorderRef.current = mr;
        mr.start();
        toast("Recording started");
        // Start duration timer
        setRecordingMs(0);
        if (recordingTimer) {
          window.clearInterval(recordingTimer);
        }
        const timerId = window.setInterval(() => {
          setRecordingMs((ms) => ms + 1000);
        }, 1000);
        setRecordingTimer(timerId as unknown as number);
      } catch (err: any) {
        const message =
          err?.name === "NotAllowedError"
            ? "Microphone access was denied. Please enable mic permissions in your browser settings."
            : err?.name === "NotFoundError"
              ? "No microphone was found on this device."
              : "Could not start recording. Please try again.";
        setMicError(message);
        toast.error(message);
      }
    }

    // Stop recording, upload audio, transcribe with progress, and save as a Brain Dump.
    // This replaces the previous stopVoice with a more robust version.
    async function stopVoice() {
      try {
        // Stop the recorder, get recorded Blob named audioBlob
        mediaRecorderRef.current?.stop();
        // Clear timer
        if (recordingTimer) {
          window.clearInterval(recordingTimer);
          setRecordingTimer(null);
        }
        // Upload + transcribe
        if (typeof audioBlob === "undefined" || !audioBlob) {
          toast.error("No audio captured. Please try recording again.");
          return;
        }
        setIsUploadingAudio(true);
        setTranscriptionProgress(10);
        // 1) Generate upload URL
        const uploadUrl = await generateUploadUrl({});
        setTranscriptionProgress(30);
        // 2) Upload to Convex storage
        const res = await fetch(uploadUrl as string, {
          method: "POST",
          headers: { "Content-Type": "audio/webm" },
          body: audioBlob,
        });
        if (!res.ok) {
          setIsUploadingAudio(false);
          setTranscriptionProgress(0);
          const text = await res.text();
          throw new Error(text || "Failed to upload audio.");
        }
        const { storageId } = await res.json();
        setTranscriptionProgress(60);
        // 3) Transcribe
        const tr = await transcribeAudio({ fileId: storageId });
        setTranscriptionProgress(85);
        // 4) Persist as Brain Dump (voice note)
        const transcript: string = tr?.transcript ?? "";
        const summary: string | undefined = tr?.summary ?? undefined;
        const tags: string[] | undefined = Array.isArray(tr?.detectedTags)
          ? tr.detectedTags
          : undefined;

        // ... keep existing code (find businessId & initiativeId currently in scope)
        if (!businessId || !initiativeId) {
          throw new Error(
            "Missing business or initiative context to save voice note.",
          );
        }
        await addVoiceNoteMutation({
          businessId,
          initiativeId,
          transcript: transcript || "[empty transcript]",
          summary,
          tags,
        });
        setTranscriptionProgress(100);
        toast.success("Voice note saved.");
      } catch (err: any) {
        const msg = err?.message || "Failed to process voice note.";
        toast.error(msg);
        setMicError(msg);
      } finally {
        setIsUploadingAudio(false);
        // Reset progress after a short delay for visual feedback
        setTimeout(() => setTranscriptionProgress(0), 600);
      }
    }

    // Retry helper: clear error and attempt to start again.
    function retryVoice() {
      setMicError(null);
      startVoice();
    }

    // Add: inline save handler for typed idea
    const handleSaveIdea = async () => {
      if (!initiativeId) {
        toast("No initiative found. Run Phase 0 setup first.");
        return;
      }
      const content = (text || summary || transcript).trim();
      if (!content) {
        toast("Type an idea first.");
        return;
      }
      try {
        setSaving(true);
        const tags = tagIdea(content);
        if (addVoiceDump) {
          await addVoiceDump({
            initiativeId,
            content,
            transcript: transcript || undefined,
            summary: summary || undefined,
            tags,
          });
        } else {
          await addDump({ initiativeId, content });
        }
        setText("");
        toast.success("Saved idea.");
      } catch (e: any) {
        toast.error(e?.message || "Failed to save idea.");
      } finally {
        setSaving(false);
      }
    };

    // Add local loading state for restore
    const [lastDeletedItem, setLastDeletedItem] = React.useState<any | null>(
      null,
    );

    // Audio recording + upload + transcription
    // const mediaRecorderRef = React.useRef<MediaRecorder | null>(null);
    // const chunksRef = React.useRef<Blob[]>([]);
    // const [audioUrl, setAudioUrl] = React.useState<string>("");
    // const [uploading, setUploading] = React.useState(false);
    // const getUploadUrl = useAction(api.files.getUploadUrl as any);
    /* removed duplicate voice notes robustness state block */

    const startRecording = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          audio: true,
        });
        const mr = new MediaRecorder(stream);
        chunksRef.current = [];
        mr.ondataavailable = (e) => {
          if (e.data && e.data.size > 0) chunksRef.current.push(e.data);
        };
        mr.onstop = () => {
          const blob = new Blob(chunksRef.current, { type: "audio/webm" });
          const url = URL.createObjectURL(blob);
          setAudioUrl(url);
        };
        mediaRecorderRef.current = mr;
        mr.start();
        toast("Recording started");
      } catch (e: any) {
        toast.error(e?.message ?? "Mic permission denied");
      }
    };

    const stopRecording = () => {
      try {
        mediaRecorderRef.current?.stop();
        toast("Recording stopped");
      } catch {}
    };

    const handleUploadAndTranscribe = async () => {
      if (!audioUrl) {
        toast("Record audio first");
        return;
      }
      if (!initiativeId) {
        toast("No initiative found. Run setup first.");
        return;
      }
      try {
        setUploading(true);
        const res = await fetch(audioUrl);
        const blob = await res.blob();

        const { url } = (await getUploadUrl({})) as any;
        const putRes = await fetch(url, {
          method: "POST",
          headers: { "Content-Type": blob.type || "application/octet-stream" },
          body: blob,
        });
        if (!putRes.ok) throw new Error("Upload failed");
        const uploaded = await putRes.json(); // { storageId }
        const fileId = uploaded.storageId;

        const tx = (await transcribeAudio({ fileId })) as any;
        const tTranscript = tx?.transcript || "";
        const tSummary = tx?.summary || "";

        const tags = tagIdea((tSummary || tTranscript).trim());
        if (addVoiceDump) {
          await addVoiceDump({
            initiativeId,
            content: (text || tSummary || tTranscript || "Voice note").trim(),
            transcript: tTranscript || undefined,
            summary: tSummary || undefined,
            tags,
            audioFileId: fileId,
          } as any);
        } else {
          await addDump({
            initiativeId,
            content: tSummary || "Voice note",
          } as any);
        }
        setText("");
        toast.success("Voice note uploaded and saved.");
      } catch (e: any) {
        toast.error(e?.message ?? "Upload/transcription failed");
      } finally {
        setUploading(false);
      }
    };

    const brainDumpSection = <DashboardBrainDumpSection businessId={business?._id} />;

  // Add helper: local usage and streaks
  function useTemplateOrderingAndStreak() {
